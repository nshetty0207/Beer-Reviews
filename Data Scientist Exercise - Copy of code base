# Importing all the needed Packages 

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns

## Exploratory Data Analysis

# Loading the Dataset in the dataframe format 
data=pd.read_csv("beer_reviews.csv")
data.head(8)

# Data Description
data.describe()

# Data Information
data.info()

# This graph shows a linear variation of the  review_appearance with review_aroma
sns.barplot(data["review_appearance"], data["review_aroma"])

/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

## TASK 1 - Which brewery produces the strongest beers by ABV%?

# Transfered the required features into a new data
data_brewery=data[["brewery_name","beer_name","beer_abv"]]
data_brewery.head()

# Performed groupby and aggregation function the required features
data_brewery_abv=data_brewery.groupby(("brewery_name","beer_name")).agg({"beer_abv":[np.size,np.mean]})
data_brewery_abv.head(15)

# Grouped all the breweries and took the mean of the abv% of each of them
data_brewery_abv_mean=data_brewery_abv.groupby("brewery_name").mean()
#data_brewery_abv_mean.head(15)
data_brewery_abv_mean.columns=("Size","ABV_mean")
data_brewery_abv_mean_sorted=data_brewery_abv_mean.sort_values("ABV_mean",ascending=False).reset_index()
data_brewery_abv_mean_sorted.head(15)

# ANSWER : Hence the brewery_name "Schorschbräu" produces the trongest beers in ABV%

/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

##TASK 2 - If you had to pick 3 beers to recommend using only this data,which would you pick?

# Transfered the required features into a new data
top_beers = data[["beer_name","beer_abv","review_overall"]]
top_beers.head()

# Found the count of each beer
top_beers["Review_Overall_Count"]=top_beers.groupby(["beer_name"])["review_overall"].transform("count")
top_beers.head(15)

# Used Matplotlib library to get an idea on how many reviews/count was received based on overall reviews for each beer
plt.hist(top_beers["Review_Overall_Count"], bins=30)
plt.xlabel("Review_Overall_Count")
plt.show()

# Took the mean of the overall review of the beers
top_beers["Review_Overall_Mean"]=top_beers.groupby(["beer_name"])["review_overall"].transform("mean")
top_beers.head(10)

# Decided to take a minimum of 50 overall reviews for a beer 
top_beers_count=top_beers[top_beers["Review_Overall_Count"] >= 50]
top_beers_count_group=top_beers_count.groupby("beer_name").head(1).sort_values("Review_Overall_Mean",ascending=False)
top_beers_count_group.head(3)


#ANSWER : Hence my top 3 beers would be "Armand'4 Oude Geuze Lente (Spring)","Hoppy Birthday"," Geuze Cuvée J&J (Joost En Jessie) Blauw (Blue)" and based my result on 2 factors mainly:
#First being the minimum number of reviews I considered which is 50 for each beer review
#Secondly the mean of the "review_overall" beers

/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

TASK 3 - Which of the factors (aroma, taste, appearance, palette) are most important in determining the overall quality of a beer?

# Grouped the required features - aroma, taste, appearance, palette and performed aggregated function on them
quality_beer_grouped= data.groupby("beer_name").agg({"review_aroma":"mean","review_taste":"mean","review_appearance":"mean","review_palate":"mean","review_overall":"mean"})
quality_beer_grouped.head(10)

#Performed correlation analysis between all the features
correlation=quality_beer_grouped.corr()
correlation

# Created an heatmap using seaborn which shows an better visualization of the correlation between the overall review and the other features
plt.figure(figsize=(10,10))
masking = np.zeros_like(correlation)
masking[np.triu_indices_from(masking, k=1)] = True
sns.heatmap(correlation, annot=True, linewidths=.8,mask=masking, cmap="coolwarm")

# ANSWER : Hence from the heatmap we get an better inference that :
# Firstly the the "review_taste" has the highest positive correlation of (0.88) with the overall quality of the beer
# Secondly the the "review_palate" has an  second highest positive correlation of (0.81) with the overall quality of the beer
# Thirdly the the "review_aroma" has a positive correlation of (0.75) with the overall quality of the beer
# Fourthly the the "review_appeareance" has a low positive correlation of (0.63) with the overall quality of the beer

/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

TASK 4 - Lastly, if I typically enjoy a beer due to its aroma and appearance, which beer style should I try?

# Transfered the required features into a new data and grouped the data and performed an aggregate function on it
beer_style=data[["review_aroma","review_appearance", "beer_style"]]
beer_style_grouped=beer_style.groupby("beer_style").agg({"review_aroma":[np.mean],"review_appearance":[np.mean]})
beer_style_grouped.head(10)

#Took the average of the means of "review_aroma" and "review_appearance" for each "beer_style"  
beer_style_grouped["Total_Mean_Ratings"]=((beer_style_grouped["review_aroma","mean"] + beer_style_grouped["review_appearance","mean"])/2)
beer_style_grouped.sort_values("Total_Mean_Ratings",ascending=False).head(10)

# ANSWER : Hence the Beer you would like is :
# "American Double / Imperial Stout" and "Russian Imperial Stout"

/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

# Exploratory Data Analysis showing the linear variation of 2 features "review_overall" and "review_appearance"

data_analysis=data.groupby("beer_style").agg({"review_overall":[np.mean],"review_appearance":[np.mean]})

data_analysis_review_overall = data_analysis["review_overall","mean"].values
data_analysis_review_appearance = data_analysis["review_appearance","mean"].values

plt.figure(figsize=(5, 5))
plt.scatter(data_analysis_review_overall, data_analysis_review_appearance)
plt.xlabel("review_overall")
plt.ylabel("review_appearance")
plt.title("review_overall vs review_appearance")
plt.show()


# Exploratory Data Analysis showing the linear variation of 2 features "review_aroma" and "review_appearance"
# Hence the "review_appearance" and the "review_aroma" vary linearly with the "review_overall".Also to be noticed is we don see any outliers between them

data_analysis=data.groupby("beer_style").agg({"review_aroma":[np.mean],"review_appearance":[np.mean]})

data_analysis_review_overall = data_analysis["review_aroma","mean"].values
data_analysis_review_appearance = data_analysis["review_appearance","mean"].values

plt.figure(figsize=(5, 5))
plt.scatter(data_analysis_review_overall, data_analysis_review_appearance)
plt.xlabel("review_aroma")
plt.ylabel("review_appearance")
plt.title("review_aroma vs review_appearance")
plt.show()

/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

## Machine Learning Model

data_analysis=data.groupby("beer_style").agg({"review_overall":[np.mean],"review_appearance":[np.mean],"review_aroma":[np.mean]})
x1=data_analysis["review_appearance","mean"].values
x2=data_analysis["review_aroma","mean"].values
X=pd.DataFrame({'review_appearance':x1, 'review_aroma':x2})
y=data_analysis["review_overall","mean"].values

# Imported the packages from sklearn and split the data into training set and testing set

from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
linear_mod = LinearRegression()
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)

# Fitted the trained model on to the data and then found the importance of the coefficients were the index 0 tells the importance of the feature "review_appearence" and index 2 tells the importance of the feature "review_aroma" on the model

linear_mod=linear_mod.fit(X_train,y_train)
linear_mod.coef_

# Predicted the output of the model using the testing set

prediction=linear_mod.predict(X_test)
print(prediction)

# Plotted a scatter plot of the y_test and predicted value,hence getting a linear variation between the 2 features 

plt.scatter(y_test,prediction)
plt.xlabel('Y Test')
plt.ylabel('prediction')

# Calculated the RMSE and MSE score indicating the Residual error is very small (i.e the difference between the actual output and predicted output is very small)

from sklearn import metrics
print('MSE:', metrics.mean_squared_error(y_test, prediction))
print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, prediction)))

# Hence from this model we can now in the future predict the "review_overall" score with high accuracy if the review_appearence" and "review_aroma" scores are known

